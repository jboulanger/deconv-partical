{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP deconvolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google collab:\n",
    "!pip install git+https://github.com/jboulanger/Analysis-of-Microscopy-Images-in-Python.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction de transfert optique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import mean_squared_error\n",
    "from mug import deconvolution\n",
    "from mug import data\n",
    "from mug import utils\n",
    "\n",
    "shape = [64,256,256]\n",
    "pixel_size = [100,80,80]\n",
    "otf, psf = deconvolution.otf_generator(shape,pixel_size,500,1,1.3)([0,0,0,0.0])\n",
    "plt.imshow(utils.slice3d(np.log(1e-6+np.fft.fftshift(psf))))\n",
    "plt.axis('off')\n",
    "plt.title('Point spread function');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation d'une image test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur(img, otf):\n",
    "    \"\"\"Blur the image with the OTF\n",
    "    Parameters\n",
    "    ----------\n",
    "    img : image\n",
    "    otf : optical transfer function (same size as the image)\n",
    "    Returns\n",
    "    -------\n",
    "    the blurred image\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return img\n",
    "\n",
    "# Generate a test sample\n",
    "sample = 0.1 + 1000 * data.fibers(shape,pixel_size,L=500,smooth=30)\n",
    "# Simulate the image of the sample\n",
    "blurred = blur(sample, otf)\n",
    "# Add some noise\n",
    "blurred = np.random.poisson(blurred)\n",
    "# Compute the MSE between the blurred image and the original sample\n",
    "mse_blurred = mean_squared_error(sample, blurred)\n",
    "# Display the images\n",
    "utils.show_image_list(\n",
    "    [utils.mip3d(x) for x in [sample, blurred]],\n",
    "    ['Sample', f'Blurred (MSE:{mse_blurred:.2f})'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtre de Wiener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconvolve_wiener(img, otf, snr):\n",
    "    \"\"\"Deconvolve the image using a Wiener filter / regularized inverse filter    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data       : numpy array\n",
    "    otf        : numpy array of the same size than data\n",
    "    snr        : signal to noise ratio\n",
    "    Returns\n",
    "    -------\n",
    "    estimate   : estimated image\n",
    "    \"\"\"\n",
    "    filter = 1 # TODO\n",
    "    return np.real(np.fft.ifftn(filter * np.fft.fftn(img)))\n",
    "\n",
    "estimate_wnr = deconvolve_wiener(blurred, otf, 10)\n",
    "mse_wnr = mean_squared_error(sample, estimate_wnr)\n",
    "utils.show_image_list(\n",
    "    [utils.mip3d(x) for x in [sample, estimate_wnr]],\n",
    "    ['Sample', f'Wiener(MSE:{mse_wnr:.2f})'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithme de Gold-Meinel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconvolve_gold_meinel(data, otf, background=0, iterations=100, acceleration=1.3, smooth=0):\n",
    "    \"\"\"Deconvolve data according to the given otf using a Gold-Meinel\n",
    "    algorithm\n",
    "    Parameters\n",
    "    ----------\n",
    "    data         : numpy array\n",
    "    otf          : numpy array of the same size than data\n",
    "    background   : background level\n",
    "    iterations   : number of iterations\n",
    "    acceleration : acceleration parameter\n",
    "    Returns\n",
    "    -------\n",
    "    estimate   : estimated image\n",
    "    dkl        : Kullback Leibler divergence\n",
    "\n",
    "    [1] R. Gold. Rapp. tech. ANL-6984. Argonne National Lab., Ill., 1964.\n",
    "\n",
    "    \"\"\"    \n",
    "    epsilon = 1e-6 # a little number    \n",
    "    estimate = np.maximum(data-background, epsilon)\n",
    "    for k in range(iterations):\n",
    "        blurred = 1 # TODO\n",
    "        ratio = 1 # TODO\n",
    "        estimate = estimate * 1 # TODO    \n",
    "    return estimate\n",
    "\n",
    "estimate_gm = deconvolve_gold_meinel(blurred, otf)\n",
    "mse_gm = mean_squared_error(sample, estimate_gm)\n",
    "utils.show_image_list(\n",
    "    [utils.mip3d(x) for x in [sample, estimate_gm]],\n",
    "    ['Sample', f'G-M (MSE:{mse_gm:.2f})'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm de Richardson-Lucy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconvolve_richardson_lucy(data, otf, background=0, iterations=100):\n",
    "    \"\"\"Deconvolve data according to the given otf using a Richardson-Lucy\n",
    "    algorithm\n",
    "    Parameters\n",
    "    ----------\n",
    "    data       : numpy array\n",
    "    otf        : numpy array of the same size than data\n",
    "    background : background level\n",
    "    iterations : number of iterations\n",
    "    Returns\n",
    "    -------\n",
    "    estimate   : estimated image\n",
    "    dkl        : Kullback Leibler divergence\n",
    "\n",
    "    [1] W. H. Richardson, Bayesian-Based Iterative Method of Image Restoration,\n",
    "        J. Opt. Soc. Am., vol. 62, no. 1, pp. 55â€“59, Jan. 1972,\n",
    "        doi: 10.1364/JOSA.62.000055.\n",
    "    [2] L. B. Lucy, An iterative technique for the rectification of observed\n",
    "        distributions, The Astronomical Journal, vol. 79, p. 745, Jun. 1974,\n",
    "        doi: 10.1086/111605.\n",
    "\n",
    "    \"\"\"\n",
    "    epsilon = 1e-6 # a little number\n",
    "    estimate = np.maximum(data-background, epsilon)\n",
    "    dkl = np.zeros(iterations)\n",
    "    for k in range(iterations):\n",
    "        blurred = 1 # TODO\n",
    "        ratio = 1 # TODO\n",
    "        estimate = estimate * 1\n",
    "        dkl[k] = np.mean(blurred - data + data * np.log(np.maximum(ratio, epsilon)))\n",
    "    return estimate, dkl\n",
    "\n",
    "estimate_rl = deconvolve_richardson_lucy(blurred, otf)\n",
    "mse_rl = mean_squared_error(sample, estimate_rl)\n",
    "utils.show_image_list(\n",
    "    [utils.mip3d(x) for x in [sample, estimate_rl]],\n",
    "    ['Sample', f'R-L (MSE:{mse_rl:.2f})'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimization de la variation total (TV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconvolve_total_variation(\n",
    "        data:np.ndarray,\n",
    "        otf:np.ndarray,\n",
    "        background=0.,        \n",
    "        regularization:float=0.5,\n",
    "        max_iter:int=100,\n",
    "        step_size:float=1,\n",
    "        beta:float=0.1) -> np.ndarray:\n",
    "    \"\"\"Deconvolve the image with a total variation regularization\n",
    "    Parameters\n",
    "    ----------\n",
    "    data       : numpy array\n",
    "    otf        : numpy array of the same size than data\n",
    "    background : background as float or nd.array\n",
    "    ...\n",
    "    Returns\n",
    "    -------\n",
    "    estimate   : estimated image\n",
    "    \"\"\"\n",
    "    from scipy import ndimage\n",
    "    epsilon = 1e-6    \n",
    "    estimate = np.maximum(np.real(np.fft.ifftn(otf * np.fft.fftn(data-background))), epsilon)\n",
    "    D = [np.array([0,-1,1]).reshape(s) for s in [[1,1,3],[1,3,1],[3,1,1]]]    \n",
    "    Dstar = [np.array([-1,1,0]).reshape(s) for s in [[1,1,3],[1,3,1],[3,1,1]]]    \n",
    "    Hstarf = np.real(np.fft.ifftn(np.conjugate(otf) * np.fft.fftn(data)))\n",
    "    HtH = np.conjugate(otf) * otf\n",
    "    for _ in range(max_iter):\n",
    "        G = [ndimage.convolve(estimate, d, mode='reflect') for d in D]\n",
    "        N = np.sqrt(sum([np.square(g) for g in G]) + beta)\n",
    "        curv = sum([ndimage.convolve(g/N,d) for g,d in zip(G,Dstar)])\n",
    "        veloc = 1 # TODO        \n",
    "        estimate = np.maximum(estimate - step_size * veloc, 0)\n",
    "    return estimate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e68ceeda825b2c8089ac761ae3799fedf379d81d72f169d795a3d12706b96a70"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
